bf16: false
fp16: false
fsdp: []
seed: 42
tf32: null
debug: []
optim: ADAMW_TORCH
_n_gpu: 0
do_eval: false
no_cuda: false
use_cpu: false
do_train: false
is_debug: false
run_name: tetrahedron-3m-og
use_ipex: false
adafactor: false
data_seed: null
deepspeed: null
hub_token: null
log_level: passive
max_steps: 50000
ray_scope: last
report_to:
- wandb
s3_folder: checkpoints/tetrahedron-3m-og
adam_beta1: !!python/object/apply:numpy._core.multiarray.scalar
- !!python/object/apply:numpy.dtype
  args:
  - f8
  - false
  - true
  state: !!python/tuple
  - 3
  - <
  - null
  - null
  - null
  - -1
  - -1
  - 0
- !!binary |
  zczMzMzM7D8=
adam_beta2: !!python/object/apply:numpy._core.multiarray.scalar
- !!python/object/apply:numpy.dtype
  args:
  - f8
  - false
  - true
  state: !!python/tuple
  - 3
  - <
  - null
  - null
  - null
  - -1
  - -1
  - 0
- !!binary |
  K4cW2c737z8=
do_predict: false
eval_delay: 0
eval_steps: null
local_rank: 0
optim_args: null
output_dir: /mnt/disks/persist/checkpoints/tetrahedron-3m-og
past_index: -1
save_steps: 100
bucket_name: devinterp-language
ddp_backend: null
ddp_timeout: 1800
fsdp_config:
  xla: false
  xla_fsdp_v2: false
  min_num_params: 0
  xla_fsdp_grad_ckpt: false
label_names:
- input_ids
push_to_aws: true
push_to_hub: false
torchdynamo: null
adam_epsilon: !!python/object/apply:numpy._core.multiarray.scalar
- !!python/object/apply:numpy.dtype
  args:
  - f8
  - false
  - true
  state: !!python/tuple
  - 3
  - <
  - null
  - null
  - null
  - -1
  - -1
  - 0
- !!binary |
  Ooww4o55RT4=
disable_tqdm: false
fp16_backend: auto
hub_model_id: null
hub_strategy: EVERY_SAVE
warmup_ratio: 0
warmup_steps: 0
weight_decay: !!python/object/apply:numpy._core.multiarray.scalar
- !!python/object/apply:numpy.dtype
  args:
  - f8
  - false
  - true
  state: !!python/tuple
  - 3
  - <
  - null
  - null
  - null
  - -1
  - -1
  - 0
- !!binary |
  mpmZmZmZqT8=
eval_on_start: false
eval_strategy: 'NO'
jit_mode_eval: false
learning_rate: !!python/object/apply:numpy._core.multiarray.scalar
- !!python/object/apply:numpy.dtype
  args:
  - f8
  - false
  - true
  state: !!python/tuple
  - 3
  - <
  - null
  - null
  - null
  - -1
  - -1
  - 0
- !!binary |
  /Knx0k1iUD8=
logging_steps: 10
max_grad_norm: 1
mp_parameters: ''
save_strategy: STEPS
split_batches: null
torch_compile: false
tpu_num_cores: null
bf16_full_eval: false
fp16_full_eval: false
fp16_opt_level: O1
save_log_steps: 0
use_mps_device: false
checkpoints_dir: /mnt/disks/persist/checkpoints/
group_by_length: false
hub_always_push: false
num_generations: 5
save_only_model: false
dispatch_batches: null
full_determinism: false
generation_steps: 1000
hub_private_repo: false
ignore_data_skip: false
log_on_each_node: true
logging_strategy: STEPS
num_train_epochs: 3
save_safetensors: true
save_total_limit: null
ddp_bucket_cap_mb: null
greater_is_better: null
log_level_replica: warning
lr_scheduler_type: CONSTANT
push_to_hub_token: null
save_on_each_node: false
tpu_metrics_debug: false
accelerator_config:
  even_batches: true
  non_blocking: false
  split_batches: false
  dispatch_batches: null
  use_configured_state: false
  use_seedable_sampler: true
  gradient_accumulation_kwargs: null
batch_eval_metrics: false
length_column_name: length
logging_first_step: true
torch_compile_mode: null
delete_after_upload: false
evaluation_strategy: null
fsdp_min_num_params: 0
lr_scheduler_kwargs: {}
neftune_noise_alpha: null
skip_memory_metrics: true
auto_find_batch_size: false
dataloader_drop_last: false
optim_target_modules: null
overwrite_output_dir: false
prediction_loss_only: false
push_to_hub_model_id: null
dataloader_pin_memory: true
ddp_broadcast_buffers: null
metric_for_best_model: null
remove_unused_columns: false
torch_compile_backend: null
dataloader_num_workers: 0
eval_do_concat_batches: true
eval_use_gather_object: false
gradient_checkpointing: false
half_precision_backend: auto
label_smoothing_factor: 0
load_best_model_at_end: false
logging_nan_inf_filter: true
resume_from_checkpoint: null
eval_accumulation_steps: null
generation_temperatures:
- 0.8
- 1
- 1.2
per_gpu_eval_batch_size: null
torch_empty_cache_steps: null
per_gpu_train_batch_size: null
push_to_hub_organization: null
include_tokens_per_second: false
dataloader_prefetch_factor: null
ddp_find_unused_parameters: null
include_inputs_for_metrics: false
per_device_eval_batch_size: 8
use_legacy_prediction_loop: false
gradient_accumulation_steps: 1
per_device_train_batch_size: 25
dataloader_persistent_workers: false
gradient_checkpointing_kwargs: null
include_num_input_tokens_seen: false
fsdp_transformer_layer_cls_to_wrap: null
restore_callback_states_from_checkpoint: false
